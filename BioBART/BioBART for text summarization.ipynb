{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60b7074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "\n",
    "#checkpoint = \"facebook/bart-base\"\n",
    "#checkpoint = \"facebook/bart-large\"\n",
    "checkpoint = \"GanjinZero/biobart-base\"\n",
    "#checkpoint = \"GanjinZero/biobart-large\"\n",
    "#checkpoint = \"GanjinZero/biobart-v2-base\"\n",
    "#checkpoint = \"GanjinZero/biobart-v2-large\"\n",
    "#dataset_config = \"mimic-iii\"\n",
    "dataset_config = \"mimic-cxr\"\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d00187",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datasets\n",
    "#dataset_config = 'mimic-cxr','mimic-iii'  \n",
    "#split = 'train','validate',test\n",
    "\n",
    "def build_dataset(dataset_config, tokenizer, split):\n",
    "    data_path = '/nfs/turbo/umms-vgvinodv/data/bioNLP23-Task-1B/data/'\n",
    "    findings_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.findings.tok')\n",
    "    impression_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.impression.tok')\n",
    "\n",
    "    findings = [line.strip() for line in open(findings_file_path).readlines()]\n",
    "    impression = [line.strip() for line in open(impression_file_path).readlines()]\n",
    "\n",
    "    dataset = datasets.Dataset.from_dict({\"text\":findings,\"summary\":impression}) \n",
    "    \n",
    "    \n",
    "    def preprocess_function(samples):\n",
    "        texts = samples[\"text\"]\n",
    "        summaries = samples[\"summary\"]\n",
    "        prompt = \" The main impression based on the given FINDINGS section of the chest X-ray report are:\"\n",
    "        #prompt = \"summarize: \"\n",
    "\n",
    "        inputs = [_text+prompt for _text in texts]\n",
    "        model_inputs = tokenizer(inputs)\n",
    "        \n",
    "        labels = tokenizer(text_target=summaries, max_length=1024, truncation=True)\n",
    "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "        return model_inputs\n",
    "    \n",
    "    dataset = dataset.map(preprocess_function, batched=True, num_proc=4, remove_columns=list(dataset.features))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00fcb979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eca39ee207d44d0aaa1a47bcada93cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/125417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4db13886ba44bd8e518b7a9449742a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1624 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_data = build_dataset(dataset_config,tokenizer,\"train\")\n",
    "tokenized_eval_data = build_dataset(dataset_config,tokenizer,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4618373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49cf3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from radgraph import F1RadGraph\n",
    "from f1chexbert import F1CheXbert\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "f1radgraph = F1RadGraph(reward_level=\"partial\")\n",
    "f1chexbert = F1CheXbert(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc9167f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    result[\"F1RadGraph\"] = f1radgraph(hyps=decoded_preds, refs=decoded_labels)[0]\n",
    "    \n",
    "    class_report_5 = f1chexbert(hyps=decoded_preds,refs=decoded_labels)[-1]\n",
    "    result[\"F1CheXbert\"] = class_report_5[\"micro avg\"][\"f1-score\"]\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06c29069",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156780' max='156780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156780/156780 5:21:08, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>F1radgraph</th>\n",
       "      <th>F1chexbert</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.037100</td>\n",
       "      <td>1.150739</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.385700</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>0.355200</td>\n",
       "      <td>0.560500</td>\n",
       "      <td>15.982800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.941500</td>\n",
       "      <td>1.100073</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.296500</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.377000</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>16.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.885100</td>\n",
       "      <td>1.066168</td>\n",
       "      <td>0.435500</td>\n",
       "      <td>0.297600</td>\n",
       "      <td>0.408200</td>\n",
       "      <td>0.408200</td>\n",
       "      <td>0.373700</td>\n",
       "      <td>0.592100</td>\n",
       "      <td>15.831900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.836700</td>\n",
       "      <td>1.049886</td>\n",
       "      <td>0.440700</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.590100</td>\n",
       "      <td>16.749400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>1.049267</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.588700</td>\n",
       "      <td>15.894700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.766300</td>\n",
       "      <td>1.049064</td>\n",
       "      <td>0.434000</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>0.407100</td>\n",
       "      <td>0.407200</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>15.974800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.727100</td>\n",
       "      <td>1.049103</td>\n",
       "      <td>0.439000</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>0.411700</td>\n",
       "      <td>0.411400</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.583700</td>\n",
       "      <td>16.501200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.703900</td>\n",
       "      <td>1.054283</td>\n",
       "      <td>0.447800</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.595400</td>\n",
       "      <td>16.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>1.066923</td>\n",
       "      <td>0.446500</td>\n",
       "      <td>0.305200</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.592400</td>\n",
       "      <td>16.629300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.648200</td>\n",
       "      <td>1.069488</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>0.311400</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.390900</td>\n",
       "      <td>0.592300</td>\n",
       "      <td>16.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.625100</td>\n",
       "      <td>1.079728</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.307100</td>\n",
       "      <td>0.418800</td>\n",
       "      <td>0.418900</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>0.602400</td>\n",
       "      <td>16.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.599800</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>0.314200</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.423900</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.591600</td>\n",
       "      <td>16.633600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.576400</td>\n",
       "      <td>1.103547</td>\n",
       "      <td>0.452600</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.607600</td>\n",
       "      <td>16.773400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>1.114150</td>\n",
       "      <td>0.447800</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.418800</td>\n",
       "      <td>0.418300</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>16.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>1.120246</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.414400</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.385100</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>16.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.531200</td>\n",
       "      <td>1.129138</td>\n",
       "      <td>0.444800</td>\n",
       "      <td>0.303200</td>\n",
       "      <td>0.416700</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.383200</td>\n",
       "      <td>0.575800</td>\n",
       "      <td>16.711200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>1.137739</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>0.304800</td>\n",
       "      <td>0.418700</td>\n",
       "      <td>0.418200</td>\n",
       "      <td>0.388400</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>16.793100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.500900</td>\n",
       "      <td>1.146398</td>\n",
       "      <td>0.444500</td>\n",
       "      <td>0.301700</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.597700</td>\n",
       "      <td>16.768500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.492400</td>\n",
       "      <td>1.151303</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.380900</td>\n",
       "      <td>0.595100</td>\n",
       "      <td>16.643500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.493100</td>\n",
       "      <td>1.154132</td>\n",
       "      <td>0.445400</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.383500</td>\n",
       "      <td>0.602200</td>\n",
       "      <td>16.709400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=156780, training_loss=0.6754704514941569, metrics={'train_runtime': 19268.9263, 'train_samples_per_second': 130.175, 'train_steps_per_second': 8.136, 'total_flos': 2.4242863811152896e+17, 'train_loss': 0.6754704514941569, 'epoch': 20.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model_name = checkpoint.split(\"/\")[-1]\n",
    "batch_size = 16\n",
    "num_train_epochs = 20 #5\n",
    "save_path: str=\"/nfs/turbo/umms-vgvinodv/models/finetuned-checkpoints/radsum\"\n",
    "save_path = f\"{save_path}/{model_name}-{dataset_config}\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=save_path,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    overwrite_output_dir = True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    #push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_data,\n",
    "    eval_dataset=tokenized_eval_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325137b",
   "metadata": {},
   "source": [
    "## Evaluate on Hidden Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202fe10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76ac9c31ea494bf19638eedbfc65ee9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [63/63 00:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.865882396697998,\n",
       " 'eval_rouge1': 0.279,\n",
       " 'eval_rouge2': 0.1552,\n",
       " 'eval_rougeL': 0.2517,\n",
       " 'eval_rougeLsum': 0.2515,\n",
       " 'eval_F1RadGraph': 0.0968,\n",
       " 'eval_F1CheXbert': 0.3869,\n",
       " 'eval_gen_len': 17.875,\n",
       " 'eval_runtime': 123.0317,\n",
       " 'eval_samples_per_second': 8.128,\n",
       " 'eval_steps_per_second': 0.512,\n",
       " 'epoch': 20.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_test_data = build_dataset(dataset_config,tokenizer,\"test.hidden\")\n",
    "trainer.evaluate(hidden_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b6571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
