{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a3ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datasets\n",
    "#dataset_config = 'mimic-cxr','mimic-iii'  \n",
    "#split = 'train','validate',test\n",
    "\n",
    "max_input_length = 768\n",
    "\n",
    "def build_dataset(dataset_config, tokenizer, split):\n",
    "    data_path = '/nfs/turbo/umms-vgvinodv/data/bioNLP23-Task-1B/data/'\n",
    "    findings_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.findings.tok')\n",
    "    impression_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.impression.tok')\n",
    "    image_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.image.tok')\n",
    "\n",
    "\n",
    "    findings = [line.strip() for line in open(findings_file_path).readlines()]\n",
    "    impression = [line.strip() for line in open(impression_file_path).readlines()]\n",
    "    \n",
    "    def generate_image_path(line):\n",
    "        return str(Path(data_path).joinpath(dataset_config).joinpath(line.strip().split(',')[0]))\n",
    "    image_paths = [generate_image_path(line) for line in open(image_file_path).readlines()]\n",
    "\n",
    "    dataset = datasets.Dataset.from_dict({\"text\":findings,\"summary\":impression}) \n",
    "    #dataset = datasets.Dataset.from_dict({\"text\":findings,\"summary\":impression,\"img_path\":image_paths}) \n",
    "    \n",
    "    \n",
    "    def preprocess_function(samples):\n",
    "        texts = samples[\"text\"]\n",
    "        summaries = samples[\"summary\"]\n",
    "        prompt = \"The main impression based on the given FINDINGS section of the chest X-ray report are:\"\n",
    "        \n",
    "        def generate_input(_text,_summary):\n",
    "            return \" \".join([_text,prompt,_summary])\n",
    "\n",
    "        inputs = [generate_input(_text,_summary) for _text,_summary in zip(texts,summaries)]\n",
    "        model_inputs = tokenizer(inputs)\n",
    "        \n",
    "        return model_inputs\n",
    "    \n",
    "    dataset = dataset.map(preprocess_function, batched=True, num_proc=4, remove_columns=list(dataset.features))\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datasets\n",
    "\n",
    "dataset_config, split = 'mimic-cxr', 'train'\n",
    "data_path = '/nfs/turbo/umms-vgvinodv/data/bioNLP23-Task-1B/data/'\n",
    "\n",
    "findings_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.findings.tok')\n",
    "impression_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.impression.tok')\n",
    "image_file_path = Path(data_path).joinpath(dataset_config).joinpath(split+'.image.tok')\n",
    "\n",
    "\n",
    "findings = [line.strip() for line in open(findings_file_path).readlines()]\n",
    "impression = [line.strip() for line in open(impression_file_path).readlines()]\n",
    "\n",
    "def generate_image_path(line):\n",
    "    return str(Path(data_path).joinpath(dataset_config).joinpath(line.strip().split(',')[0]))\n",
    "image_paths = [generate_image_path(line) for line in open(image_file_path).readlines()]\n",
    "\n",
    "dataset = datasets.Dataset.from_dict({\"text\":findings,\"summary\":impression,\"img_path\":image_paths}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset[\"img_path\"][0])\n",
    "print(len(dataset))\n",
    "\n",
    "def check_img_exists(example):\n",
    "    return example[\"img_path\"].split('/')[10] != 'p10'\n",
    "\n",
    "dataset = dataset.filter(check_img_exists)\n",
    "\n",
    "print(dataset[\"img_path\"][0])\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48016e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage, torch, torchvision\n",
    "\n",
    "# Prepare the image:\n",
    "img_pth = dataset[\"img_path\"][10]\n",
    "img = skimage.io.imread(img_pth)\n",
    "skimage.io.imshow(img) \n",
    "skimage.io.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1558d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/RyanWangZf/MedCLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbffd9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall transformers -y\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24137493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548b318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from medclip import MedCLIPModel, MedCLIPVisionModelViT, MedCLIPVisionModel\n",
    "from medclip import MedCLIPProcessor\n",
    "from PIL import Image\n",
    "\n",
    "sample = dataset[10]\n",
    "# prepare for the demo image and texts\n",
    "processor = MedCLIPProcessor()\n",
    "image = Image.open(sample[\"img_path\"])\n",
    "text = sample[\"summary\"]\n",
    "inputs = processor(\n",
    "    text=text,\n",
    "    images=image, \n",
    "    return_tensors=\"pt\", \n",
    "    padding=True\n",
    "    )\n",
    "\n",
    "# pass to MedCLIP model\n",
    "model = MedCLIPModel(vision_cls=MedCLIPVisionModel)\n",
    "model.from_pretrained()\n",
    "model.cuda()\n",
    "outputs = model(**inputs)\n",
    "print(outputs.keys())\n",
    "print(outputs['logits'])\n",
    "# dict_keys(['img_embeds', 'text_embeds', 'logits', 'loss_value', 'logits_per_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405a42b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
